{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G1Bcwk5HfeTr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install matplotlib\n",
    "#!pip install torch\n",
    "#!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom IPython import display\\nfrom collections import namedtuple\\nimport torch.nn as nn\\nimport torch.optim as optim\\nfrom collections import deque\\nfrom itertools import count\\nimport torch.nn.functional as F\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import neccessary libraries\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import copy\n",
    "import numpy as np\n",
    "import math as m\n",
    "import random as r\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\"\"\"\n",
    "from IPython import display\n",
    "from collections import namedtuple\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from itertools import count\n",
    "import torch.nn.functional as F\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ox3GzGtjBiB",
    "outputId": "e50abe91-530a-4e0a-f0db-bf460a759c8f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "# Register the environment\n",
    "gym.register(\n",
    "    id='vehicleRouting-v0',\n",
    "    entry_point='Julian_1cyc_Zelda_my_vre_no_norm:vehicleRoutingEnv',\n",
    "    kwargs={'current_customer_list': None, 'current_truck_capacity': None, 'total_truck_capacity': None, 'depot_location': None}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_instance_creator(cust_max_dem, truck_cap, num_cust, num_row, num_col):\n",
    "    depot = (r.random(),r.random())\n",
    "    occupied_coords=[]\n",
    "    occupied_coords.append(depot)\n",
    "    current_customer_list=[]\n",
    "    current_customer_list.append(depot)\n",
    "    for cust in range(num_cust):\n",
    "        customer=[]\n",
    "        coord=depot\n",
    "        while coord in occupied_coords:\n",
    "            coord=(r.random(),r.random())\n",
    "        occupied_coords.append(coord)\n",
    "        customer.append(coord)\n",
    "        demand=(r.randint(1,cust_max_dem))\n",
    "        customer.append(demand)\n",
    "        distance_to_depot=dist = (m.sqrt(((depot[0]-coord[0])**2)+(depot[1]-coord[1])**2))\n",
    "        customer.append(distance_to_depot)\n",
    "        distance_to_truck=distance_to_depot\n",
    "        customer.append(distance_to_truck)\n",
    "        position_to_depot=(coord[0]-depot[0],coord[1]-depot[1])\n",
    "        customer.append(position_to_depot)\n",
    "        position_to_truck=position_to_depot\n",
    "        customer.append(position_to_truck)\n",
    "        current_customer_list.append(customer)\n",
    "    current_truck_capacity=truck_cap\n",
    "    total_truck_capacity=truck_cap\n",
    "    return current_customer_list, current_truck_capacity, total_truck_capacity, depot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gaoVhwzgvS3t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate random problem instance, generating random values (some within range, like demand) for matrices and locations\n",
    "#self, info_vector, customer_location_matrix, truck_location_matrix, customer_demand_matrix, truck_capacity_matrix, customer_timeframe_matrix, truck_timeframe_matrix, customer_location_tuple_list\n",
    "#Generate instance function would be entirely seperate from solver\n",
    "#Outer creates problem instance, then calls solve entire problem, input tuple of location\n",
    "def instance_creator(cust_max_dem, truck_cap, num_cust, num_row, num_col):\n",
    "    depot = (r.randint(0,num_row-1),r.randint(0,num_col)-1)\n",
    "    occupied_coords=[]\n",
    "    occupied_coords.append(depot)\n",
    "    current_customer_list=[]\n",
    "    current_customer_list.append(depot)\n",
    "    for cust in range(num_cust):\n",
    "        customer=[]\n",
    "        coord=depot\n",
    "        while coord in occupied_coords:\n",
    "            coord=(r.randint(0,num_row-1),r.randint(0,num_col)-1)\n",
    "        occupied_coords.append(coord)\n",
    "        customer.append(coord)\n",
    "        demand=(r.randint(1,cust_max_dem))\n",
    "        customer.append(demand)\n",
    "        distance_to_depot=dist = (m.sqrt(((depot[0]-coord[0])**2)+(depot[1]-coord[1])**2))\n",
    "        customer.append(distance_to_depot)\n",
    "        distance_to_truck=distance_to_depot\n",
    "        customer.append(distance_to_truck)\n",
    "        position_to_depot=(coord[0]-depot[0],coord[1]-depot[1])\n",
    "        customer.append(position_to_depot)\n",
    "        position_to_truck=position_to_depot\n",
    "        customer.append(position_to_truck)\n",
    "        current_customer_list.append(customer)\n",
    "    current_truck_capacity=truck_cap\n",
    "    total_truck_capacity=truck_cap\n",
    "    return current_customer_list, current_truck_capacity, total_truck_capacity, depot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the problem values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining problem instance variables\n",
    "#Changing the numbers, changes the single instance NN is training\n",
    "\n",
    "# KEVIN\n",
    "cust_max_dem = 5\n",
    "truck_cap = 12\n",
    "num_cust = 5\n",
    "num_row = 10\n",
    "num_col = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create instance and initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KntSbl8GvVwx",
    "outputId": "758132de-dec2-4d98-9618-de9f9b703b7d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating problem instance using defined variables\n",
    "current_customer_list, current_truck_capacity, total_truck_capacity, depot_location = \\\n",
    "normalized_instance_creator(cust_max_dem, truck_cap, num_cust, num_row, num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Customer List: [(0.5768101854667281, 0.7034053729236469), [(0.8755596467755387, 0.777306500028592), 1, 0.3077541506132545, 0.3077541506132545, (0.2987494613088105, 0.07390112710494512), (0.2987494613088105, 0.07390112710494512)], [(0.18828648106524504, 0.44527832952677504), 1, 0.46645497040406975, 0.46645497040406975, (-0.3885237044014831, -0.25812704339687187), (-0.3885237044014831, -0.25812704339687187)], [(0.28548799690043625, 0.15966594787479405), 3, 0.6168639881720371, 0.6168639881720371, (-0.2913221885662919, -0.5437394250488529), (-0.2913221885662919, -0.5437394250488529)], [(0.35697170912422715, 0.7807824488410736), 5, 0.23305829218915078, 0.23305829218915078, (-0.21983847634250098, 0.07737707591742671), (-0.21983847634250098, 0.07737707591742671)], [(0.16597485699631576, 0.5617573489747922), 1, 0.4345685559356624, 0.4345685559356624, (-0.4108353284704124, -0.14164802394885467), (-0.4108353284704124, -0.14164802394885467)]]\n",
      "Depot: (0.5768101854667281, 0.7034053729236469)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current Customer List: {current_customer_list}\")\n",
    "print(f\"Depot: {depot_location}\")\n",
    "print(current_truck_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEVIN\n",
    "#current_customer_list=[(5, 1),\n",
    "# [(9, 3), 5, 4.47213595499958, 4.47213595499958, (4, 2), (4, 2)],\n",
    "# [(8, 1), 3, 3.0, 3.0, (3, 0), (3, 0)]]\n",
    "#depot_location = (5,1)\n",
    "#current_truck_capacity=10\n",
    "#total_truck_capacity=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "uG1-QJMpjqBs",
    "outputId": "13c937ee-33c1-4985-cb66-e47612c2f3e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the environment\n",
    "# Making the enviromenet, using the created matrices from the creeated problem instance\n",
    "env = gym.make('vehicleRouting-v0', current_customer_list=current_customer_list, \\\n",
    "               current_truck_capacity=current_truck_capacity, \\\n",
    "               total_truck_capacity=total_truck_capacity, depot_location=depot_location)\n",
    "#Checks if you are in ipython enviroment\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "#If true, then import display which is used later for the visual plots\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "#Makes the plots interactive, so that the plots are visualized and changing as new data is being created\n",
    "plt.ion()\n",
    "#Check if there is dedicated GPU, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/mambaforge-pypy3/envs/rl/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/kevin/mambaforge-pypy3/envs/rl/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/kevin/mambaforge-pypy3/envs/rl/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:137: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(\n",
      "/home/kevin/mambaforge-pypy3/envs/rl/lib/python3.10/site-packages/gym/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "  logger.warn(\"Casting input x to numpy array.\")\n"
     ]
    }
   ],
   "source": [
    "#Defining the environment action space number and reset environment\n",
    "n_actions=env.action_space.n\n",
    "state, info =env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: [[1, 0, 0, 0, 0, 0], 0.5768101854667281, 0.7034053729236469, 0.8755596467755387, 0.777306500028592, 1, 0.3077541506132545, 0.3077541506132545, 0.2987494613088105, 0.07390112710494512, 0.2987494613088105, 0.07390112710494512, 0.18828648106524504, 0.44527832952677504, 1, 0.46645497040406975, 0.46645497040406975, -0.3885237044014831, -0.25812704339687187, -0.3885237044014831, -0.25812704339687187, 0.28548799690043625, 0.15966594787479405, 3, 0.6168639881720371, 0.6168639881720371, -0.2913221885662919, -0.5437394250488529, -0.2913221885662919, -0.5437394250488529, 0.35697170912422715, 0.7807824488410736, 5, 0.23305829218915078, 0.23305829218915078, -0.21983847634250098, 0.07737707591742671, -0.21983847634250098, 0.07737707591742671, 0.16597485699631576, 0.5617573489747922, 1, 0.4345685559356624, 0.4345685559356624, -0.4108353284704124, -0.14164802394885467, -0.4108353284704124, -0.14164802394885467, 12, 12]\n",
      "States List: [1, 0, 0, 0, 0, 0, 0.5768101854667281, 0.7034053729236469, 0.8755596467755387, 0.777306500028592, 1, 0.3077541506132545, 0.3077541506132545, 0.2987494613088105, 0.07390112710494512, 0.2987494613088105, 0.07390112710494512, 0.18828648106524504, 0.44527832952677504, 1, 0.46645497040406975, 0.46645497040406975, -0.3885237044014831, -0.25812704339687187, -0.3885237044014831, -0.25812704339687187, 0.28548799690043625, 0.15966594787479405, 3, 0.6168639881720371, 0.6168639881720371, -0.2913221885662919, -0.5437394250488529, -0.2913221885662919, -0.5437394250488529, 0.35697170912422715, 0.7807824488410736, 5, 0.23305829218915078, 0.23305829218915078, -0.21983847634250098, 0.07737707591742671, -0.21983847634250098, 0.07737707591742671, 0.16597485699631576, 0.5617573489747922, 1, 0.4345685559356624, 0.4345685559356624, -0.4108353284704124, -0.14164802394885467, -0.4108353284704124, -0.14164802394885467, 12, 12]\n",
      "Visited: []\n",
      "Unvisited: [1, 2, 3, 4, 5]\n",
      "Current Customer List: [(0.5768101854667281, 0.7034053729236469), [(0.8755596467755387, 0.777306500028592), 1, 0.3077541506132545, 0.3077541506132545, (0.2987494613088105, 0.07390112710494512), (0.2987494613088105, 0.07390112710494512)], [(0.18828648106524504, 0.44527832952677504), 1, 0.46645497040406975, 0.46645497040406975, (-0.3885237044014831, -0.25812704339687187), (-0.3885237044014831, -0.25812704339687187)], [(0.28548799690043625, 0.15966594787479405), 3, 0.6168639881720371, 0.6168639881720371, (-0.2913221885662919, -0.5437394250488529), (-0.2913221885662919, -0.5437394250488529)], [(0.35697170912422715, 0.7807824488410736), 5, 0.23305829218915078, 0.23305829218915078, (-0.21983847634250098, 0.07737707591742671), (-0.21983847634250098, 0.07737707591742671)], [(0.16597485699631576, 0.5617573489747922), 1, 0.4345685559356624, 0.4345685559356624, (-0.4108353284704124, -0.14164802394885467), (-0.4108353284704124, -0.14164802394885467)]]\n",
      "Truck Current Capacity: 12\n",
      "Truck Max Capacity: 12\n",
      "Depot Location: (0.5768101854667281, 0.7034053729236469)\n",
      "Position List: [1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Testing the render function\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining transition\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "#Creating replay memory class\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "#        new_transition = Transition(*args)\n",
    "#        # Check for an existing transition with matching state and action\n",
    "#        match_found = False\n",
    "#        for existing_transition in self.memory:\n",
    "#            state_match = torch.equal(existing_transition.state, new_transition.state)\n",
    "#            action_match = torch.equal(existing_transition.action, new_transition.action)\n",
    "#            if state_match and action_match:\n",
    "#                match_found = True\n",
    "#                break\n",
    "#        if not match_found:\n",
    "#            self.memory.append(new_transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return r.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining DQN class, input layer is the observations (flattened states list)\n",
    "#Two layers of 128 nodes each\n",
    "#Output layer of the number of actions\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        print(f'*** Initializing with {n_observations}, {n_actions}')\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 32)\n",
    "        self.ln1 = nn.LayerNorm(32)\n",
    "        self.layer2 = nn.Linear(32, 16)\n",
    "        self.ln2 = nn.LayerNorm(16)\n",
    "        self.layer3 = nn.Linear(16, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.ln1(self.layer1(x)))\n",
    "        x = F.relu(self.ln2(self.layer2(x)))\n",
    "#        x = F.relu(self.layer3(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Single Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_action(state, exclude_indices):\n",
    "    global steps_done\n",
    "    global global_eps_threshold\n",
    "\n",
    "    DEBUG_SELECT= False\n",
    "    sample = r.random()\n",
    "#Eps threshold is used for exploitation vs exploration\n",
    "#When the sample is greater than the calculated eps threshold, then the NN is taking the policy selected action (exploitation)\n",
    "#When the sample is not greater, then the NN is choosing a random action (exploration)\n",
    "#The ending eps value is added to the difference between the starting and ending epsilon value, which would\n",
    "#This is multiplied by e^(-1 times the number of steps over the decay value of 1000). Meaning that as the number\n",
    "#of steps increase than -1 is multiplied by a larger fraction and therefore, the expression, m.exp(-1. * steps_done / EPS_DECAY)\n",
    "#is becoming a smaller fraction. And since the fraction is being multplied by eps end and the difference of end and start,\n",
    "#the entire express is decreasing over time, and therefore, more samples are greater than the threshold leading\n",
    "#to more exploitation\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        m.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    global_eps_threshold = eps_threshold\n",
    "    # DEBUG\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            # Create a mask for the actions to exclude\n",
    "            action_values = policy_net(state)\n",
    "            #print(f\"action_values: {action_values}\")\n",
    "            #Create array of boolean values for the mask\n",
    "            exclude_mask = torch.full_like(action_values, float('0'), dtype=torch.bool)\n",
    "            #Sets corresponding values in row 0 of exclude mask to True if exclude indicies indicates it\n",
    "            exclude_mask[0,exclude_indices] = True\n",
    "            #print(f\"exclude_mask: {exclude_mask}\")\n",
    "            #Sets masked out corresponding values to negative infinity so that no matter what, the network will not choose them\n",
    "            #because of their high negative reward (negative inf)\n",
    "            masked_action_values = torch.where(exclude_mask, torch.tensor(float('-inf')), action_values)\n",
    "            if DEBUG_SELECT:\n",
    "                print(f\"Masked Action Values: {masked_action_values}\")\n",
    "            return masked_action_values.max(1).indices.view(1,1)\n",
    "            # return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        sample_action = env.action_space.sample()\n",
    "        while sample_action in exclude_indices:\n",
    "            sample_action = env.action_space.sample()\n",
    "        return torch.tensor([[sample_action]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_costs = []\n",
    "episode_losses= []\n",
    "\n",
    "def plot_costs(title_str = '',show_result=False):\n",
    "    plt.figure(1)\n",
    "    costs_t = torch.tensor(episode_costs, dtype=torch.float)\n",
    "    losses = torch.tensor(episode_losses, dtype=torch.float)\n",
    "    epoches= list(range(1,len(costs_t)+1))\n",
    "\n",
    "    if show_result == False:\n",
    "        plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    # Plot the first series on ax1\n",
    "    color = 'tab:blue'\n",
    "    if show_result:\n",
    "        ax1.set_title(f'Result ({title_str})')\n",
    "    else:\n",
    "        ax1.set_title(f'Training... ({title_str})')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Negative Cost', color=color)\n",
    "    if len(costs_t) >=100:\n",
    "        ax1.plot(epoches[101:], costs_t[101:], color=color)\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "        means = costs_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax1.plot(epoches[101:], means[101:].numpy(), color='tab:orange')\n",
    "    else:\n",
    "        ax1.plot(epoches, costs_t, color=color)\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    \n",
    "    # Create ax2 that shares the same x-axis with ax1\n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:green'\n",
    "    ax2.set_ylabel('Nnet Loss', color=color)  \n",
    "    if len(costs_t) >=100:\n",
    "        means = losses.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax2.plot(epoches[101:], means[101:].numpy(), color=color)\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "    else:\n",
    "        ax2.plot(epoches, losses, color=color)\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    fig.tight_layout()  # To ensure a neat layout\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "def orig_plot_costs(title_str = '',show_result=False):\n",
    "    plt.figure(1)\n",
    "    costs_t = torch.tensor(episode_costs, dtype=torch.float)\n",
    "    losses = torch.tensor(episode_losses, dtype=torch.float)\n",
    "\n",
    "    if show_result:\n",
    "        plt.title(f'Result ({title_str})')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title(f'Training... ({title_str})')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Cost')\n",
    "    if len(costs_t) >= 100:\n",
    "        plt.plot(costs_t[101:].numpy())\n",
    "        plt.plot(losses[101:].numpy())\n",
    "    else:\n",
    "        plt.plot(costs_t.numpy())\n",
    "        plt.plot(losses.numpy())\n",
    "        \n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(costs_t) >= 100:\n",
    "        means = costs_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means[101:].numpy())\n",
    "#    plt.pause(0.0001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt():\n",
    "    DEBUG_OPT=True\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    # with torch.no_grad():\n",
    "    #    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        action_values = target_net(non_final_next_states)\n",
    "        exclude_mask = torch.full_like(action_values, float('0'), dtype=torch.bool)\n",
    "        #Sets corresponding values in row 0 of exclude mask to True if exclude indicies indicates it\n",
    "#        exclude_indices = [env.get_invalid_ones_w_states(e.tolist()) for e in non_final_next_states.to('cpu')]\n",
    "        exclude_indices=[]\n",
    "        for row_idx, cols in enumerate(exclude_indices):\n",
    "            for col_idx in cols:\n",
    "                exclude_mask[row_idx, col_idx] = True\n",
    "        masked_action_values = torch.where(exclude_mask, torch.tensor(float('-inf')), action_values)\n",
    "        next_state_values[non_final_mask] = masked_action_values.max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    if DEBUG_OPT and opt_cnt%100:\n",
    "        print(f\"state: {state_batch}\")\n",
    "        pritn(f\"action: {action_batch}\")\n",
    "        print(f\"reward: {reward_batch}\")\n",
    "        print(f\"expected_state_action_values: {expected_state_action_values}\")\n",
    "        print(f\"state_action_values: {state_action_values}\")\n",
    "        pritn(f\"loss: {loss}\")\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    global opt_cnt;\n",
    "    global opt_loss;\n",
    "    DEBUG = False\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    # with torch.no_grad():\n",
    "    #    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        action_values = target_net(non_final_next_states)\n",
    "        exclude_mask = torch.full_like(action_values, float('0'), dtype=torch.bool)\n",
    "        #Sets corresponding values in row 0 of exclude mask to True if exclude indicies indicates it\n",
    "        exclude_indices = [env.get_invalid_ones_w_states(e.tolist()) for e in non_final_next_states.to('cpu')]\n",
    "        for row_idx, cols in enumerate(exclude_indices):\n",
    "            for col_idx in cols:\n",
    "                exclude_mask[row_idx, col_idx] = True\n",
    "        masked_action_values = torch.where(exclude_mask, torch.tensor(float('-inf')), action_values)\n",
    "        next_state_values[non_final_mask] = masked_action_values.max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    opt_loss = loss\n",
    "    opt_cnt+=1\n",
    "    if DEBUG and opt_cnt%100 == 1:\n",
    "        print(f\"opt_cnt: {opt_cnt} ******************************************************************************************************************************************\")\n",
    "        print(f\"state: {state_batch}\")\n",
    "        print(f\"action: {action_batch.tolist()}\")\n",
    "        print(f\"reward: {reward_batch}\")\n",
    "        print(f\"masked_action_values: {masked_action_values}\")\n",
    "        print(f\"next_state_values: {next_state_values}\")\n",
    "        print(f\"expected_state_action_values: {expected_state_action_values}\")\n",
    "        print(f\"state_action_values: {state_action_values.tolist()}\")\n",
    "        print(f\"loss: {loss}\")\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run x number of episodes and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Initializing with 55, 4\n",
      "*** Initializing with 55, 4\n"
     ]
    }
   ],
   "source": [
    "#Reset NN\n",
    "#Initialize parameters\n",
    "#BATCH_SIZE = 128\n",
    "BATCH_SIZE = 64 # was 256\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9 # was 0.9\n",
    "EPS_END = 0.0 # was 0.05\n",
    "EPS_DECAY = 1000 # was 1000\n",
    "TAU = 0.02 # was 0.05\n",
    "LR = 1e-3 # MODIFIED from 1e-5\n",
    "#LR = 1e-6 (worked)\n",
    "REPLAY_MEM_SIZE = 1000 # was 1000\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.5)\n",
    "memory = ReplayMemory(REPLAY_MEM_SIZE)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "opt_cnt = 0\n",
    "opt_loss=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5768101854667281, 0.7034053729236469),\n",
       " [(0.8755596467755387, 0.777306500028592),\n",
       "  1,\n",
       "  0.3077541506132545,\n",
       "  0.3077541506132545,\n",
       "  (0.2987494613088105, 0.07390112710494512),\n",
       "  (0.2987494613088105, 0.07390112710494512)],\n",
       " [(0.18828648106524504, 0.44527832952677504),\n",
       "  1,\n",
       "  0.46645497040406975,\n",
       "  0.46645497040406975,\n",
       "  (-0.3885237044014831, -0.25812704339687187),\n",
       "  (-0.3885237044014831, -0.25812704339687187)],\n",
       " [(0.28548799690043625, 0.15966594787479405),\n",
       "  3,\n",
       "  0.6168639881720371,\n",
       "  0.6168639881720371,\n",
       "  (-0.2913221885662919, -0.5437394250488529),\n",
       "  (-0.2913221885662919, -0.5437394250488529)],\n",
       " [(0.35697170912422715, 0.7807824488410736),\n",
       "  5,\n",
       "  0.23305829218915078,\n",
       "  0.23305829218915078,\n",
       "  (-0.21983847634250098, 0.07737707591742671),\n",
       "  (-0.21983847634250098, 0.07737707591742671)],\n",
       " [(0.16597485699631576, 0.5617573489747922),\n",
       "  1,\n",
       "  0.4345685559356624,\n",
       "  0.4345685559356624,\n",
       "  (-0.4108353284704124, -0.14164802394885467),\n",
       "  (-0.4108353284704124, -0.14164802394885467)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_customer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train the neural network\n",
    "#If dedicated GPU is found, run 6000 episodes, else run 600 episodes\n",
    "if torch.cuda.is_available():\n",
    "    num_episodes = 20000\n",
    "else:\n",
    "    num_episodes = 800\n",
    "best_cost = -1e16\n",
    "best_mean_cost=-1e16\n",
    "best_episode = 0\n",
    "best_mean_episode = 0\n",
    "last_best_episode = 0\n",
    "best_path = []\n",
    "DEBUG = False\n",
    "PLOT = True\n",
    "long_path=[]\n",
    "long_path_visual=[]\n",
    "long_visited=[]\n",
    "\n",
    "long_cost = 0\n",
    "flat_states=[]\n",
    "global_eps_threshold = 1.0\n",
    "longest_path=[]\n",
    "longest_path_cnt=0\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    \"\"\"\n",
    "    if i_episode%5==0:\n",
    "    #Creating problem instance using defined variables\n",
    "        info_vector, customer_location_matrix, truck_location_matrix, \\\n",
    "        customer_demand_matrix, truck_capacity_matrix, customer_location_list = \\\n",
    "        instance_creator(cust_max_dem, truck_cap, num_cust, num_row, num_col)\n",
    "        #For this instance, set starting truck location to depot location\n",
    "        truck_location_matrix[info_vector[0][0],info_vector[0][1]]=1\n",
    "        truck_start_location = (np.where(truck_location_matrix==1)[0][0], np.where(truck_location_matrix==1)[1][0])\n",
    "        #Set at the location of the truck, the starting demand to the max truck capacity\n",
    "        truck_capacity_matrix[info_vector[0][0],info_vector[0][1]]=info_vector[1]\n",
    "        state, info = env.update(info_vector, customer_location_matrix, truck_location_matrix, customer_demand_matrix,\\\n",
    "        truck_capacity_matrix, customer_location_list, truck_start_location)\n",
    "    # Initialize the environment and get it's state\n",
    "    else:\n",
    "    \"\"\"\n",
    "    state, info = env.reset()\n",
    "    env.reorder_customers()\n",
    "    env.update()\n",
    "    state = env.get_state()\n",
    "    if DEBUG: \n",
    "        print(f\"[{i_episode}] State: {state} *************************************************************\\n\\n\")\n",
    "        print(f\"Longest path ({longest_path_cnt}) {longest_path}\")\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    \n",
    "    total_cost = 0.0\n",
    "    visited = [0]\n",
    "    path=[]\n",
    "    rewards=[]\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    for t in count():\n",
    "        #Print information for debugging and training\n",
    "        invalid_ones = env.get_invalid_ones()\n",
    "        if DEBUG:\n",
    "            print(f\"{t} -------------------------------------------------\")\n",
    "            print(f'invalid_ones = {invalid_ones}')\n",
    "        action = select_action(state, invalid_ones)\n",
    "        if DEBUG: \n",
    "            print(f\"action selected: {action.item()}\")\n",
    "            print(f\"path so far: {path}\") \n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        #if reward <= -env.max_dist:\n",
    "        #    reward = -1.0\n",
    "        if DEBUG: \n",
    "            print(f\"Step done ---------------------\")\n",
    "            print(f\"cur_cust_list: {env.current_customer_list}\")\n",
    "            print(f\"observation: {observation}\")\n",
    "            print(f\"reward: {reward}\")\n",
    "            print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "        v = env.get_visited()\n",
    "        u = env.get_unvisited()\n",
    "        if DEBUG: \n",
    "            print(f\"visited: {v}\")\n",
    "            print(f\"unvisited: {u}\")\n",
    "        total_cost = total_cost + reward\n",
    "        visited = copy.deepcopy(info[\"visited\"])\n",
    "        if action.item() not in visited:\n",
    "            visited.append(action.item())\n",
    "        rewards.append(-reward)\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "        visited = copy.deepcopy(info[\"visited\"])\n",
    "        unvisited = copy.deepcopy(info[\"unvisited\"])\n",
    "        if action.item()==2:\n",
    "            path.append([action.item(), visited, unvisited])\n",
    "        else:\n",
    "            path.append([action.item(), \"no customer selected\", \"\"])\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        if state is not None:\n",
    "            temp = [t.tolist() for t in flat_states]\n",
    "            #print(f\"temp: {temp}\")\n",
    "            if state.tolist() not in temp:\n",
    "                flat_states.append(state)\n",
    "        if next_state is not None:\n",
    "            temp = [t.tolist() for t in flat_states]\n",
    "            if next_state.tolist() not in temp:\n",
    "                flat_states.append(next_state)\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        #print(f\"state: {state}\")\n",
    "        \n",
    "        #print(f\"action: {action.item()}\")\n",
    "        # print(f\"Memory length: {len(memory)}\")\n",
    "       # Perform one step of the optimization (on the policy network)\n",
    "        if DEBUG:\n",
    "            print(\"Calling optimize_model ...\")\n",
    "        optimize_model()\n",
    "        if DEBUG:\n",
    "            print(\"Done optimize model.\")\n",
    "       # Soft update of the target network's weights\n",
    "       #     + (1  )\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict: \n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)            \n",
    "        if done:\n",
    "            if DEBUG:\n",
    "                print(f\"******** Total cost: {total_cost}\")\n",
    "            episode_costs.append(total_cost)\n",
    "            episode_losses.append(opt_loss)\n",
    "            # TODO: the code below has no effect\n",
    "            memory_size = len(memory)\n",
    "            if memory_size > REPLAY_MEM_SIZE:\n",
    "                replay = True\n",
    "            else:\n",
    "                replay = False\n",
    "            mean = np.mean(episode_costs[-100:])\n",
    "            if len(path) > longest_path_cnt:\n",
    "                longest_path_cnt=len(path)\n",
    "                longest_path=path\n",
    "            if total_cost == best_cost:\n",
    "                last_best_episode=i_episode\n",
    "            if total_cost>best_cost:\n",
    "                best_cost=total_cost\n",
    "                best_path=path\n",
    "                best_episode = i_episode\n",
    "                last_best_episode=i_episode\n",
    "            if mean>best_mean_cost:\n",
    "                best_mean_cost=mean\n",
    "                best_mean_episode=i_episode\n",
    "            if total_cost<long_cost:\n",
    "                long_cost= total_cost\n",
    "                long_path=path\n",
    "                long_path_visual=[]\n",
    "                for value in long_path:\n",
    "                    if value[0]==1:\n",
    "                        long_path_visual.append(\"Right\")\n",
    "                        long_path_visual.append(value[1])\n",
    "                    elif value[0]==2:\n",
    "                        long_path_visual.append(\"Select\")\n",
    "                        long_path_visual.append(value[1])\n",
    "                    elif value[0]==3:\n",
    "                        long_path_visual.append(\"Depot\")\n",
    "                        long_path_visual.append(value[1])\n",
    "                long_visited=visited\n",
    "                long_rewards=rewards\n",
    "            title_str = f'[{global_eps_threshold:.4f}: {current_lr:.8f}: {opt_loss:.6f}: {long_cost:.4f}/{best_episode}/{last_best_episode}/{i_episode}] [{best_mean_episode}] Mean Cost:{best_mean_cost:.4f}/{mean:.4f}, Best_Cost: {best_cost:.4f}, Longest_Path_Length: {longest_path_cnt}'\n",
    "            if DEBUG == False:\n",
    "                if PLOT == True:\n",
    "                    plot_costs(title_str=title_str)\n",
    "            break\n",
    "    scheduler.step()\n",
    "print(f\"[{best_episode}: Best cost: {best_cost} and best path: {best_path}\")\n",
    "print('Complete')\n",
    "# HERE\n",
    "if DEBUG == False:\n",
    "    if PLOT == True:\n",
    "        plot_costs(show_result=True) \n",
    "        plt.ioff()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename='layernorm-normalize-debug-2cust-scheduler-nodedop-to_zero_explore.nnet'\n",
    "torch.save(policy_net.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_path_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_customer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.current_customer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14.94427190999916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1=4.47213595499958/env.max_dist; dist2=3/env.max_dist; print(f\"dist1: {dist1}, dist2: {dist2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_states observation: [0, 0, 1, 5, 1, 9, 3, 0, 4.47213595499958, 2.23606797749979, 4, 2, 1, 2, 8, 1, 0, 3.0, 0.0, 3, 0, 0, 0, 7, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_customer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_path_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [t.tolist() for t in flat_states]\n",
    "for i in lists:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_path)*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "current_length = 0\n",
    "\n",
    "index=0\n",
    "marked=False\n",
    "lengths=[]\n",
    "for num in long_path:\n",
    "    # Check if the current number is 1\n",
    "    if num == 1 or num==0:\n",
    "        # Increase the length of the current sequence\n",
    "        current_length += 1\n",
    "        # Update the maximum length if the current sequence is longer\n",
    "        if current_length>max_length:\n",
    "            max_length=current_length\n",
    "            if marked == False:\n",
    "                max_index=index\n",
    "            else:\n",
    "                marked=True\n",
    "    else:\n",
    "        lengths.append(current_length)\n",
    "        # Reset the current sequence length if the current number is not 1\n",
    "        current_length = 0\n",
    "        marked=False\n",
    "    index=index+1    \n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_path[279716]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_customer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(current_customer_list)):\n",
    "    x=current_customer_list[0][0]\n",
    "    y=current_customer_list[0][1]\n",
    "    dist = m.sqrt((x-current_customer_list[i][0][0])**2+(y-current_customer_list[i][0][1])**2)\n",
    "    print(f\"[{i}] {dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 40000\n",
    "else:\n",
    "    num_episodes = 800\n",
    "DEBUG = True\n",
    "PLOT = False\n",
    "flat_states=[]\n",
    "global_eps_threshold = 1.0\n",
    "i_episode = 10000\n",
    "state, info = env.reset()\n",
    "env.reorder_customers()\n",
    "env.update()\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "total_cost = 0.0\n",
    "visited = [0]\n",
    "current_lr = optimizer.param_groups[0]['lr']\n",
    "path=[]\n",
    "if DEBUG:\n",
    "    print(f\"Initial state: {state}\")\n",
    "for t in count():\n",
    "    #Print information for debugging and training\n",
    "    invalid_ones = env.get_invalid_ones()\n",
    "    if DEBUG:\n",
    "        print(f\"{t} -------------------------------------------------\")\n",
    "        print(f'invalid_ones = {invalid_ones}')\n",
    "    action = select_action(state, invalid_ones)\n",
    "    if DEBUG: \n",
    "        print(f\"action selected: {action.item()}\")\n",
    "        print(f\"path so far: {path}\") \n",
    "    observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "    if DEBUG: \n",
    "        print(f\"Step done ---------------------\")\n",
    "        print(f\"cur_cust_list: {env.current_customer_list}\")\n",
    "        print(f\"observation: {observation}\")\n",
    "        print(f\"reward: {reward}\")\n",
    "        print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "    v = env.get_visited()\n",
    "    u = env.get_unvisited()\n",
    "    if DEBUG: \n",
    "        print(f\"visited: {v}\")\n",
    "        print(f\"unvisited: {u}\")\n",
    "    total_cost = total_cost + reward\n",
    "    visited = copy.deepcopy(info[\"visited\"])\n",
    "    if action.item() not in visited:\n",
    "        visited.append(action.item())\n",
    "    reward = torch.tensor([reward], device=device)\n",
    "    done = terminated or truncated\n",
    "    visited = copy.deepcopy(info[\"visited\"])\n",
    "    unvisited = copy.deepcopy(info[\"unvisited\"])\n",
    "    if action.item()==2:\n",
    "        path.append([action.item(), visited, unvisited])\n",
    "    else:\n",
    "        path.append([action.item(), \"no customer selected\", \"\"])\n",
    "    if terminated:\n",
    "        next_state = None\n",
    "    else:\n",
    "        next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    # Move to the next state\n",
    "    state = next_state\n",
    "    if done:\n",
    "        if DEBUG:\n",
    "            print(f\"******** Total cost: {total_cost}\")\n",
    "        if DEBUG == False:\n",
    "            if PLOT == True:\n",
    "                plot_costs(title_str=title_str)\n",
    "        break\n",
    "    scheduler.step()\n",
    "print('Complete')\n",
    "# HERE\n",
    "if DEBUG == False:\n",
    "    if PLOT == True:\n",
    "        plot_costs(show_result=True) \n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "\n",
    "[0, 1, 0, 5, 1, 9, 3, 5, 4.47213595499958, 4.47213595499958, 4, 2, 4, 2, 8, 1, 3, 3.0, 3.0, 3, 0, 3, 0, 10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reset environment\n",
    "state, info = env.reset()\n",
    "visited = [0]\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "total_cost = 0  # Variable to store the total reward for this episode\n",
    "actions_taken = []  # List to store the actions taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#See the state info\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_invalid_ones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run first step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Second step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourth step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fifth step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sixth step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seventh step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eigth step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ninth step\n",
    "action = select_action(state, visited)\n",
    "print(f\"action selected: {action}\")\n",
    "observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "print(f\"observation: {observation}\")\n",
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}, truncated: {truncated}\")\n",
    "v = env.get_visited()\n",
    "u = env.get_unvisited()\n",
    "print(f\"visited: {v}\")\n",
    "print(f\"unvisited: {u}\")\n",
    "total_cost = total_cost + reward\n",
    "visited = copy.deepcopy(info[\"visited\"])\n",
    "if action.item() not in visited:\n",
    "    visited.append(action.item())\n",
    "done = terminated or truncated\n",
    "print(f\"Total cost so far: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
